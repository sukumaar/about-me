{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Subscribe to free newsletter </p>"},{"location":"#who-am-i","title":"Who am I \ud83e\udd13?","text":"<ul> <li>Software Engineer having around 10 years of experience in Big Data Analytics with Apache Hadoop and Apache Spark.</li> <li>Worked on Big Data technologies/framework (Spark, Hive, Kafka, HBase, Airflow, Sqoop, Flume, Oozie, Solr, Elasticsearch) with Scala and Java, also done respective installations.</li> <li>Experienced in Java and Scala languages. Expertise in Apache Spark (Spark SQL, Spark core, Spark streaming), functional programming with Scala.</li> <li>Emphasize clean coding with consideration of design patterns, programming paradigms, and TDD.</li> <li>Developed applications with agile software development methodologies (Scrum, Kanban), managed a mid-size product development team.</li> <li>Experience in Optimizing Spark jobs such as configuration tuning, code optimization, query optimization etc.</li> <li>Deployed and managed solutions on cloud environments.</li> <li>Worked on Big Data uses cases like: ETL pipeline development, streaming pipelines development, data ingestion, data analysis, data validation, migration, legacy data warehouse modernization.</li> </ul>"},{"location":"#my-tech-stack","title":"My Tech Stack \u26a1\ufe0f:","text":"<ul> <li>Programming Languages:<ul> <li>Scala, Java, Python</li> </ul> </li> <li>Bigdata Ecosystem Framework:<ul> <li>Apache Spark (Spark SQL, Spark Core, Spark Streaming), Apache Beam, Apache Hive, Apache Oozie, Apache Sqoop, Apache Airflow, Apache Kafka, Elastic Search, Apache Solr.</li> </ul> </li> <li>Containerization<ul> <li>Docker, Podman, K8s</li> </ul> </li> <li>Other Tools and Frameworks:<ul> <li>Maven, SBT, Gradle, git, gitlab, JIRA, JUnit, ScalaTest, Spock.</li> </ul> </li> </ul>"},{"location":"#some-use-cases-i-worked-on","title":"Some use cases I worked on \ud83d\udee0:","text":"<ul> <li>Big Data / Cloud<ul> <li>Lift and shift of big data applications from on-prem to cloud (GCP, Azure, AWS)</li> <li>Legacy data warehouse modernization</li> <li>Data migration</li> <li>Data Discovery</li> <li>Data validation and cleaup</li> <li>Streaming data analytics pipeline with Apache Kafka, Apache Spark</li> <li>Typical ETL (Extract Transform Load) workflows</li> </ul> </li> </ul>"},{"location":"#my-tech-blogs","title":"My tech blogs \ud83d\uddd2:","text":"<ul> <li>https://rovingdev.com/</li> </ul>"},{"location":"#links-to-connect-me","title":"Links to connect me \ud83d\ude80:","text":"<p>my blog </p> <p></p>"}]}